{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3588f584",
   "metadata": {},
   "source": [
    "# Additional NLP Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d2ca3f",
   "metadata": {},
   "source": [
    "## Tokenizatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70ceb69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The United States of America (U.S.A. or USA), is located in North America.It consists of 50 states, five major unincorporated territories, 326 Indian reservations, a federal district, and some minor possessions.[g] At 3.8 million square miles (9.8 million square kilometers), it is the world's third- or fourth-largest country by total area.[c] With a population of more than 331 million people, it is the third most populous country in the world. The national capital is Washington, D.C., and the most populous city is New York City.\n"
     ]
    }
   ],
   "source": [
    "text = '''\n",
    "The United States of America (U.S.A. or USA), is located in North America.\n",
    "It consists of 50 states, five major unincorporated territories, 326 Indian reservations, \n",
    "a federal district, and some minor possessions.[g] \n",
    "At 3.8 million square miles (9.8 million square kilometers), \n",
    "it is the world's third- or fourth-largest country by total area.[c] \n",
    "With a population of more than 331 million people, \n",
    "it is the third most populous country in the world. \n",
    "The national capital is Washington, D.C., and the most populous city is New York City.\n",
    "'''.replace('\\n', '').strip()\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcebaf10",
   "metadata": {},
   "source": [
    "## Split on spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b3f82bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"The\", \"United\", \"States\", \"of\", \"America\", \"(U.S.A.\", \"or\", \"USA),\", \"is\", \"located\", \"in\", \"North\", \"America.It\", \"consists\", \"of\", \"50\", \"states,\", \"five\", \"major\", \"unincorporated\", "
     ]
    }
   ],
   "source": [
    "for token in text.split(' ')[:20]:\n",
    "    print(f'\"{token}\"', end=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce13dbb",
   "metadata": {},
   "source": [
    "## Split on non-alpha-numeric characters\n",
    "\n",
    "`\\W`: Matches any character which is not a word character. \n",
    "If the ASCII flag is used this becomes the equivalent of `[^a-zA-Z0-9_]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10837411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"The\", \"United\", \"States\", \"of\", \"America\", \"U\", \"S\", \"A\", \"or\", \"USA\", \"is\", \"located\", \"in\", \"North\", \"America\", \"It\", \"consists\", \"of\", \"50\", \"states\", "
     ]
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "for token in re.split(r'\\W+', text)[:20]:\n",
    "    print(f'\"{token}\"', end=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbb860a",
   "metadata": {},
   "source": [
    "## Language-aware splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ece0489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"The\", \"United\", \"States\", \"of\", \"America\", \"(\", \"U.S.A.\", \"or\", \"USA\", \")\", \",\", \"is\", \"located\", \"in\", \"North\", \"America\", \".\", \"It\", \"consists\", \"of\", "
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "for token in nlp(text)[:20]:\n",
    "    print(f'\"{token}\"', end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9292e495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Let\", \"'s\", \"go\", \"to\", \"N.Y.\", \"!\", "
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "for token in nlp(\"Let's go to N.Y.!\"):\n",
    "    print(f'\"{token}\"', end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c27fd5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"I\", \"'m\", \"gon\", \"na\", \"visit\", \"New\", \"York\", \"City\", \"at\", \"6:00\", \"A.M.\", \":-)\", "
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "for token in nlp(\"I'm gonna visit New York City at 6:00 A.M. :-)\"):\n",
    "    print(f'\"{token}\"', end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d15f276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After: ['I', \"'m\", 'gon', 'na', 'visit', 'New York City', 'at', '6:00', 'A.M.', ':-)']\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "doc = nlp(\"I'm gonna visit New York City at 6:00 A.M. :-)\")\n",
    "    \n",
    "with doc.retokenize() as retokenizer:\n",
    "    for i in range(len(doc) - 3):\n",
    "        if doc[i:i+3].text == 'New York City':\n",
    "            retokenizer.merge(doc[i:i+3], attrs={\"LEMMA\": \"new york city\"})\n",
    "            \n",
    "print(\"After:\", [token.text for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f286d110",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nlp(\"I'm gonna visit New York City at 6:00 A.M. :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6923e6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'m gonna\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[1:1+3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3f07d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", "
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "for token in nlp(\"I'm gonna visit New York City at 6:00 A.M. :-)\"):\n",
    "    print(f'\"{token.lemma_}\"', end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a7baa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
